{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9237e76b-1723-43be-8a17-07a32bf3ae9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# structure of the dataset needed is :\n",
    " * train:\n",
    "   - labels  \n",
    "   - images \n",
    " * val:\n",
    "   - images  \n",
    "   - labels\n",
    "   \n",
    "   \n",
    "with labels being text files that match the image name and consist of lines of bounding boxes\n",
    "\n",
    "\n",
    "\n",
    "> transfer learning \n",
    "https://docs.ultralytics.com/yolov5/tutorials/transfer_learning_with_frozen_layers/  \n",
    "> train with custom dataset \n",
    "https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/  \n",
    "> youtube tutorial \n",
    "https://www.youtube.com/watch?v=GRtgLlwxpc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c6363c2-22eb-4e5a-bc28-77c828a73c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import comet_ml\n",
    "import numpy as np\n",
    "import albumentations\n",
    "\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import construct_dataframe,read_xml,visualize_data\n",
    "\n",
    "\n",
    "comet_ml.init()\n",
    "\n",
    "paths = [\n",
    "os.path.join(os.getcwd(),'yolo_dataset'),\n",
    "os.path.join(os.getcwd(),'yolo_dataset','train'),\n",
    "os.path.join(os.getcwd(),'yolo_dataset','train','images'),\n",
    "os.path.join(os.getcwd(),'yolo_dataset','train','labels'),\n",
    "os.path.join(os.getcwd(),'yolo_dataset','val'),\n",
    "os.path.join(os.getcwd(),'yolo_dataset','val','images'),\n",
    "os.path.join(os.getcwd(),'yolo_dataset','val', 'labels'),\n",
    "]\n",
    "\n",
    "for path in paths:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4600bf2-a4c9-4654-b3cb-5dde62967206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to-do : extract this from database and don't hard code it \n",
    "defect_categories = {\n",
    "        'punching_hole':0,\n",
    "        'welding_line':1,\n",
    "        'crescent_gap':2,\n",
    "        'water_spot':3,\n",
    "        'oil_spot':4,\n",
    "        'silk_spot':5,\n",
    "        'inclusion':6,\n",
    "        'rolled_pit':7,\n",
    "        'crease':8,\n",
    "        'waist_folding':9,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b54932-4908-4c97-bc3e-cd726706493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "#helper functions \n",
    "####\n",
    "\n",
    "########################################\n",
    "\n",
    "def calculate_bbox_parameters(xmin, xmax, ymin, ymax, image_width, image_height):\n",
    "    width = xmax - xmin\n",
    "    height = ymax - ymin\n",
    "    x_center = (xmin + xmax) / (2 * image_width)\n",
    "    y_center = (ymin + ymax) / (2 * image_height)\n",
    "    width /= image_width\n",
    "    height /= image_height\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "########################################\n",
    "\n",
    "def transform_image_and_bbs(img_arr, bboxes, h, w):\n",
    "    \"\"\"\n",
    "    :param img_arr: original image as a numpy array\n",
    "    :param bboxes: bboxes as numpy array where each row is 'x_min', 'y_min', 'x_max', 'y_max', \"class_id\"\n",
    "    :param h: resized height dimension of image\n",
    "    :param w: resized weight dimension of image\n",
    "    :return: dictionary containing {image:transformed, bboxes:['x_min', 'y_min', 'x_max', 'y_max', \"class_id\"]}\n",
    "    \"\"\"\n",
    "    # create resize transform pipeline\n",
    "    transform = albumentations.Compose(\n",
    "        [albumentations.Resize(height=h, width=w, always_apply=True)],\n",
    "        bbox_params=albumentations.BboxParams(format='pascal_voc'))\n",
    "\n",
    "    transformed = transform(image=img_arr, bboxes=bboxes)\n",
    "\n",
    "    return transformed\n",
    "\n",
    "########################################\n",
    "\n",
    "def construct_yolo_compat_data_structure(dataframe): #train or val \n",
    "    for i in ['train','val']:\n",
    "        for index,row in dataframe.iterrows():\n",
    "            #copy image to new directory\n",
    "            source_file = os.path.join(os.getcwd(),row['img_path'])\n",
    "            destination_file = os.path.join(os.getcwd(),'yolo_dataset',i,'images',f\"{row['img_id']}.jpg\")\n",
    "            \n",
    "\n",
    "            # Read the image using PIL and convert to PIL \n",
    "            image_as_numpy_arr = np.array(Image.open(source_file))\n",
    "            bbs = []\n",
    "            #convert bbs to shape that works with albumenations \n",
    "            for bb in row['bounding_boxes']:\n",
    "                #current defect_type,xmin,ymin,xmax,ymax]) convert to  'x_min', 'y_min', 'x_max', 'y_max', \"class_id\"\n",
    "                bbs.append([bb[1],bb[2],bb[3],bb[4],bb[0]])\n",
    "            h,w=640,640\n",
    "            transformed_img_and_bbs = transform_image_and_bbs(image_as_numpy_arr, np.array(bbs), h, w)\n",
    "            \n",
    "            transformed_img = transformed_img_and_bbs['image']            \n",
    "            transformed_bbs = transformed_img_and_bbs['bboxes']            \n",
    "            \n",
    "            output_image = Image.fromarray(transformed_img)\n",
    "            output_image.save(destination_file)\n",
    "\n",
    "            #os.rename(current_name, new_name)\n",
    "            bounding_boxes = ''\n",
    "\n",
    "            for bb in bbs:\n",
    "                category = bb[-1]\n",
    "                x_center, y_center, width, height = calculate_bbox_parameters(bb[0],bb[2],bb[1],bb[3],row['dimensions'][0],row['dimensions'][1])\n",
    "                bounding_boxes += f'{category} {x_center} {y_center} {width} {height}\\n'\n",
    "\n",
    "                \n",
    "                \n",
    "            labels_path = os.path.join(os.getcwd(),'yolo_dataset',i,'labels',f'{row[\"img_id\"]}.txt')\n",
    "            #write the bounding boxes to the new text structure \n",
    "            with open(labels_path, 'w') as file:\n",
    "                file.write(bounding_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe9b76e-44e9-44bc-9cca-d605282fa091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(construct_dataframe(), shuffle = True,test_size=0.2, random_state=42)\n",
    "\n",
    "construct_yolo_compat_data_structure(train_df)\n",
    "construct_yolo_compat_data_structure(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ebd371-57af-484b-ba9c-5f8433edafbc",
   "metadata": {},
   "source": [
    "# implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4568a8d2-cec2-4e38-8bb4-90b72a38130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training will be done on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.137  Python-3.9.13 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=./yolov5/data/custom_dataset.yaml, epochs=100, patience=20, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=project1, name=exp1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=project1\\exp15\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3012798 parameters, 3012782 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: sklearn.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/maherstad/project1/70e98df7aef14e0eaeb50bb10d9d1ef4\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir project1\\exp15', view at http://localhost:6006/\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: markalsa. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\marka\\Documents\\ml_projects\\Metallic-Surface-Defect-Detection\\wandb\\run-20230720_010215-1puflovj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/markalsa/project1/runs/1puflovj\" target=\"_blank\">exp1</a></strong> to <a href=\"https://wandb.ai/markalsa/project1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\marka\\Documents\\ml_projects\\Metallic-Surface-Defect-Detection\\yolo_dataset\\train\\labels... 228\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\marka\\Documents\\ml_projects\\Metallic-Surface-Defect-Detection\\yolo_dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\marka\\Documents\\ml_projects\\Metallic-Surface-Defect-Detection\\yolo_dataset\\val\\labels... 2280 im\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\marka\\Documents\\ml_projects\\Metallic-Surface-Defect-Detection\\yolo_dataset\\val\\labels.cache\n",
      "Plotting labels to project1\\exp15\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mproject1\\exp15\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100     0.384G      2.224      4.393      1.909          0        640: 100%|██████████| 1140/1140 [01:45<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.444      0.396      0.256      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100     0.432G      2.093      3.701      1.844          5        640: 100%|██████████| 1140/1140 [01:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.389      0.385       0.19     0.0836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100     0.442G      2.071       3.46      1.841          4        640: 100%|██████████| 1140/1140 [01:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.645      0.334      0.279       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      0.44G       2.05      3.167      1.857          7        640: 100%|██████████| 1140/1140 [01:47<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.493      0.404      0.266      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      0.43G      1.976      2.938      1.786          5        640: 100%|██████████| 1140/1140 [01:49<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.338      0.445      0.321      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100     0.432G      1.949      2.711      1.789          6        640: 100%|██████████| 1140/1140 [01:49<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.405      0.457      0.352      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      0.43G      1.943      2.545      1.756          3        640: 100%|██████████| 1140/1140 [01:43<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.592      0.364      0.364      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      0.43G      1.911      2.454      1.734          6        640: 100%|██████████| 1140/1140 [01:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.443      0.391      0.352      0.163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100     0.428G      1.884      2.318      1.717          8        640: 100%|██████████| 1140/1140 [01:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.399      0.504      0.408      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100      0.43G      1.888      2.339      1.731          3        640: 100%|██████████| 1140/1140 [01:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542       0.69      0.404       0.41      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100     0.426G      1.856      2.258        1.7          1        640: 100%|██████████| 1140/1140 [01:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.622      0.478      0.402      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100     0.426G      1.872      2.188      1.697          2        640: 100%|██████████| 1140/1140 [01:47<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.472      0.473      0.418      0.196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100     0.428G      1.855       2.16      1.675          6        640: 100%|██████████| 1140/1140 [01:54<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 570/570 [00:\n",
      "                   all       2280       3542      0.402      0.512      0.449      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100     0.428G      1.762        2.1      1.609          6        640:   6%|▌         | 66/1140 [00:05<01:35, 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7124/2547687869.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m model.train(data='./yolov5/data/custom_dataset.yaml',\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ultralytics\\engine\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[1;31m# attach optional HUB session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m         \u001b[1;31m# Update model and cfg after training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ultralytics\\engine\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m                 \u001b[0mddp_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setup_ddp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ultralytics\\engine\\trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[1;31m# Backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[1;31m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\comet_ml\\monkey_patching.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[0mexception_raised\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mreturn_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[0mexception_raised\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #0 meaning gpu , else cpu \n",
    "print(f'training will be done on {\"gpu\" if device == \"cuda\" else \"cpu\"}')\n",
    "\n",
    "# Load a model\n",
    "#model = YOLO('yolov8n.yaml')  # build a new model from YAML\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    "#model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "model.train(data='./yolov5/data/custom_dataset.yaml',\n",
    "            epochs=100,\n",
    "            batch = 2,\n",
    "            imgsz=640,\n",
    "            patience=20,\n",
    "            device='cuda', #gpu\n",
    "            project= 'project1', #project name \n",
    "            name = 'exp1', #experiment name\n",
    "           \n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374eb9cb-0e84-4d87-a7cd-c1f23a946d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f0bc9-a888-4c79-be3d-cd4e4a86a80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64712683-2cbc-4df9-b51e-148ac8754c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8aa0d-85e0-44a5-b675-10e75e0f916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load a model\n",
    "model = YOLO('path/to/last.pt')  # load a partially trained model\n",
    "\n",
    "# Resume training\n",
    "model.train(resume=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f4304-c916-4bbc-ab5e-22afee36e86c",
   "metadata": {},
   "source": [
    "python train.py --img 640 --epochs 3 --batch 2 --device 0 --data custom_dataset.yaml --weights yolov5m.pt \n",
    "python train.py --img 640 --epochs 3 --batch 2 --data custom_dataset.yaml --weights yolov5m.pt \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tempenv",
   "language": "python",
   "name": "tempenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
